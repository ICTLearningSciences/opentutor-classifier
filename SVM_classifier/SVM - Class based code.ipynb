{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions working:\n",
    "-     loadDataset: load the dataset \n",
    "-     preprocessing: convert into lower cases + tokenization + lemmatization\n",
    "-     split: split dataset into 75% training and 25% testing.\n",
    "-     initialize_ideal_answer: define ideal_answer\n",
    "-     encode_y = coverting y lables(categorical) to numbers(0/1)\n",
    "-     word_overlap_score: find similarity by comparing Training examples with an ideal answer\n",
    "-     alignment: returns features, which includes scores for each training examples.\n",
    "-     get_params: define parameters for the model.\n",
    "-     set_params: set the parameters of the model.\n",
    "-     trian: train the model\n",
    "-     predict: performance on the testing dataset.\n",
    "-     score: finding accuracy\n",
    "-     save: save the model locally\n",
    "-     load: load the model from local\n",
    "-     predict_probabilities: find confidence scores.\n",
    "\n",
    "Note: Dimension of the dataset is 100x2 (Its a matrix). The alignment function is made such that it will return a list (2d array)(Its a list). This is useful as we can use the same function for extracting features of training examples, testing examples, and for a new sentence ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# will remove in the development mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier:\n",
    "    def __init__(self):\n",
    "        self.tag_map = defaultdict(lambda : wn.NOUN)\n",
    "        self.tag_map['J'] = wn.ADJ\n",
    "        self.tag_map['V'] = wn.VERB\n",
    "        self.tag_map['R'] = wn.ADV\n",
    "        self.ideal_answer = None\n",
    "        self.model = None\n",
    "        \n",
    "    def loadDataset(self, file):\n",
    "        dataset = pd.read_csv(file, encoding=\"latin-1\")\n",
    "        return dataset\n",
    "    \n",
    "    def preprocessing(self, data):\n",
    "        preProcessedDataset = []\n",
    "        data = [entry.lower() for entry in data]\n",
    "        data = [word_tokenize(entry) for entry in data]\n",
    "        for index,entry in enumerate(data):\n",
    "            Final_words = []\n",
    "            word_Lemmatized = WordNetLemmatizer()\n",
    "            for word, tag in pos_tag(entry):\n",
    "                if word not in stopwords.words('english') and word.isalpha():\n",
    "                    word_Final = word_Lemmatized.lemmatize(word,self.tag_map[tag[0]])\n",
    "                    Final_words.append(word_Final)\n",
    "            preProcessedDataset.append(Final_words)\n",
    "        return preProcessedDataset\n",
    "    \n",
    "    def split(self, preProcessedDataset,Corpus):\n",
    "        Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(preProcessedDataset,Corpus['label'],test_size=0.25)\n",
    "        return Train_X, Test_X, Train_Y, Test_Y\n",
    "    \n",
    "    def initialize_ideal_answer(self, X):\n",
    "        self.ideal_answer = X[0]\n",
    "\n",
    "    def encode_y(self, Train_Y, Test_Y):\n",
    "        Encoder = LabelEncoder()\n",
    "        Train_Y = Encoder.fit_transform(Train_Y)\n",
    "        Test_Y = Encoder.fit_transform(Test_Y)\n",
    "        return Train_Y, Test_Y\n",
    "    \n",
    "    def word_overlap_score(self, Train_X, ideal_answer):\n",
    "        features = []\n",
    "        for example in Train_X:\n",
    "            intersection = set(ideal_answer).intersection(set(example)) \n",
    "            score = len(intersection)/len(set(ideal_answer))\n",
    "            features.append(score)\n",
    "        return features\n",
    "        \n",
    "    #function for extracting features\n",
    "    def alignment(self, Train_X, ideal_answer):\n",
    "        if ideal_answer is None:\n",
    "            ideal_answer = self.ideal_answer\n",
    "        features = self.word_overlap_score(Train_X, ideal_answer)\n",
    "        return (np.array(features)).reshape(-1,1)\n",
    "    \n",
    "    def get_params(self):\n",
    "        C=1.0\n",
    "        kernel='linear'\n",
    "        degree=3\n",
    "        gamma='auto'\n",
    "        probability=True\n",
    "        return C,kernel, degree, gamma, probability\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.model = svm.SVC(C = params['C'], kernel = params['kernel'], degree = params['degree'], gamma = params['gamma'], probability = params['probability'] )\n",
    "    \n",
    "    def train(self, trainFeatures, Train_Y):\n",
    "        self.model.fit(trainFeatures, Train_Y)\n",
    "        print(\"Triaining complete\")\n",
    "        \n",
    "    def predict(self, testFeatures):\n",
    "        return self.model.predict(testFeatures)\n",
    "    \n",
    "    def score(self, model_predictions, Test_Y):\n",
    "        return accuracy_score(model_predictions, Test_Y)*100\n",
    "    \n",
    "    def save(self, filename):\n",
    "        pickle.dump(self.model, open(filename, 'wb'))\n",
    "        print(\"Model saved successfully!\")\n",
    "        \n",
    "    def load(self, filename):\n",
    "        model = pickle.load(open(filename, 'rb'))\n",
    "        return model\n",
    "\n",
    "    def predict_probabilities(self, sentence):\n",
    "        return self.model.predict_proba(sentence)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = SVMClassifier()\n",
    "Corpus = obj.loadDataset('dataset.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProcessedDataset = obj.preprocessing(Corpus['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = obj.split(preProcessedDataset, Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.initialize_ideal_answer(Train_X)\n",
    "Train_Y, Test_Y = obj.encode_y(Train_Y, Test_Y)\n",
    "features = obj.alignment(Train_X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triaining complete\n"
     ]
    }
   ],
   "source": [
    "C,kernel, degree, gamma, probability = obj.get_params()\n",
    "obj.set_params(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)\n",
    "obj.train(features, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  56.00000000000001\n"
     ]
    }
   ],
   "source": [
    "testFeatures = obj.alignment(Test_X, None)\n",
    "model_predictions = obj.predict(testFeatures)\n",
    "accuracy = obj.score(model_predictions, Test_Y)\n",
    "print(\"Accuracy of the model: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "obj.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = obj.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [' More great playing: Larrys work for the Muse label in the late 80s and early 90s found him exploring the rich catalog of jazz standards that he probably grew up playing. Surrounding himself with the best musicians around, Larry sounds relaxed, focused, and totally in control. Listen to Larry take on My Funny Valentine and tell me it does not stand right up there with Chet Baker or Miles. A very fine album that you will enjoy again and again.']\n",
    "sent_proc = obj.preprocessing(sentence)\n",
    "sent_features = obj.alignment(sent_proc, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Score for Class 1 =  0.4393982033303043\n",
      "Confidence Score for Class 2 =  0.5606017966696957\n"
     ]
    }
   ],
   "source": [
    "confidence = obj.predict_probabilities(sent_features)\n",
    "print(\"Confidence Score for Class 1 = \", confidence[0][0])\n",
    "print(\"Confidence Score for Class 2 = \", confidence[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
